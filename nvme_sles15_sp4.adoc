---
sidebar: sidebar
permalink: nvme_sles15_sp4.html
keywords: nvme, linux, suse, sles, 15, sp4, server, enterprise
summary: Describes how to configure NVMe/FC for SUSE Linux Enterprise Server 15 SP4 with ONTAP
---

= NVMe-oF host configuration for SUSE Linux Enterprise Server 15 SP4 with ONTAP
:toc: macro
:hardbreaks:
:toclevels: 1
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/
:source-highlighter: highlighter.js

   
[.lead]
NVMe over Fabrics (NVMe-oF), including NVMe over Fibre Channel (NVMe/FC) and other transports, is supported with SUSE Linux Enterprise Server (SLES) 15 SP4 with Asymmetric Namespace Access (ANA). In NVMe-oF environments, ANA is the equivalent of ALUA multipathing in iSCSI and FC environments and is implemented with in-kernel NVMe multipath.

For additional details on supported configurations, see the link:https://mysupport.netapp.com/matrix/[NetApp Interoperability Matrix Tool^].

== Features

* Support for NVMe secure, in-band authentication.
* Support for persistent discovery controllers using a unique discovery NQN.

== Known limitations

SAN booting using the NVMe-oF protocol is currently not supported.

== Configure NVMe/FC

You can configure NVMe/FC for Broadcom/Emulex adapters or Marvell/Qlogic adapters.

[role="tabbed-block"]
====
.Broadcom/Emulex
--

.Steps

. Verify that you are using the recommended adapter model:
+
----
cat /sys/class/scsi_host/host*/modelname
----
+
Example output:
+
----
LPe32002 M2
LPe32002-M2
----
 
. Verify the adapter model description:
+
----
cat /sys/class/scsi_host/host*/modeldesc
----
+
*Example output*:
+
----
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter 
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----

. Verify that you are using the recommended Emulex HBA firmware versions:
+
----
cat /sys/class/scsi_host/host*/fwrev 
----
+
*Example output*:
+
----
12.8.351.47, sli-4:2:c
12.8.351.47, sli-4:2:c
----

. Verify that you are using the recommended LPFC driver version:
+
----
cat /sys/module/lpfc/version
----
+
*Example output*:
+
----
0:14.2.0.6
----

. Verify that you can view your initiator ports:
+
----
cat /sys/class/fc_host/host*/port_name
----
+
*Example output*:
+
----
0x100000109b579d5e
0x100000109b579d5f
----

. Verify that your initiator ports are online:
+
----
cat /sys/class/fc_host/host*/port_state 
----
+
*Example output*:
+
----
Online
Online
----

. Verify that the NVMe/FC initiator ports are enabled and that the target ports are visible:
+
----
cat /sys/class/scsi_host/host*/nvme_info
----
+
*Example output*:
+
In this example, one initiator port is enabled and connected with two target LIFs.
+
[subs=+quotes]
----
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b579d5e WWNN x200000109b579d5e DID x011c00 *ONLINE*
NVME RPORT WWPN x208400a098dfdd91 WWNN x208100a098dfdd91 DID x011503 *TARGET DISCSRVC ONLINE*
NVME RPORT WWPN x208500a098dfdd91 WWNN x208100a098dfdd91 DID x010003 *TARGET DISCSRVC ONLINE*

NVME Statistics
LS: Xmt 0000000e49 Cmpl 0000000e49 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000003ceb594f Issue 000000003ce65dbe OutIO fffffffffffb046f
abort 00000bd2 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr
00000000 err 00000000
FCP CMPL: xb 000014f4 Err 00012abd

NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b579d5f WWNN x200000109b579d5f DID x011b00 *ONLINE*
NVME RPORT WWPN x208300a098dfdd91 WWNN x208100a098dfdd91 DID x010c03 *TARGET DISCSRVC ONLINE*
NVME RPORT WWPN x208200a098dfdd91 WWNN x208100a098dfdd91 DID x012a03 *TARGET DISCSRVC ONLINE*

NVME Statistics
LS: Xmt 0000000e50 Cmpl 0000000e50 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000003c9859ca Issue 000000003c93515e OutIO fffffffffffaf794
abort 00000b73 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr
00000000 err 00000000
FCP CMPL: xb 0000159d Err 000135c3
----
. Reboot the host.
--

.Marvell/QLogic
--
.Steps

. The native inbox qla2xxx driver included in the SLES 15 SP4 kernel has the latest fixes essential for ONTAP support. Verify that you are running the supported adapter driver and firmware versions:
+
----
cat /sys/class/fc_host/host*/symbolic_name 
----
+
Example output:
+
----
QLE2742 FW:v9.08.02 DVR:v10.02.07.800-k QLE2742 FW:v9.08.02 DVR:v10.02.07.800-k
----

. Verify that the `ql2xnvmeenable` parameter is set to 1:
+
----
cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----
--
====

=== Enable 1MB I/O size (Optional)

include::_include/nvme/reuse_nvme_enabling_broadcom_1mb_size.adoc[]

== Configure NVMe/TCP

include::_include/nvme/reuse_configure_nvmetcp.adoc[]

.Steps

. Verify that the initiator port can fetch the discovery log page data across the supported NVMe/TCP LIFs:
+
----
nvme discover -t tcp -w host-traddr  -a traddr
----
+
*Example output*:
+
----
# nvme discover -t tcp -w 192.168.1.4 -a 192.168.1.31

Discovery Log Number of Records 10, Generation counter 119
=====Discovery Log Entry 0====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 0
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.37ba7d9cbfba11eba35dd039ea165514:subsystem.nvme_114_tcp
_1
traddr: 192.168.2.36 sectype: none
=====Discovery Log Entry 1====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 1
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.37ba7d9cbfba11eba35dd039ea165514:subsystem.nvme_114_tcp
_1
traddr: 192.168.1.31 sectype: none
=====Discovery Log Entry 2====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 0
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.37ba7d9cbfba11eba35dd039ea165514:subsystem.nvme_114_tcp
_2
traddr: 192.168.2.36 sectype: none
…
----

. Verify that all other NVMe/TCP initiator-target LIF combos can successfully fetch discovery log page data. 
+
----
nvme discover -t tcp -w host-traddr  -a traddr
----
+
*Example output:*
+
----
# nvme discover -t tcp -w 192.168.1.4 -a 192.168.1.32 
# nvme discover -t tcp -w 192.168.2.5 -a 192.168.2.36 
# nvme discover -t tcp -w 192.168.2.5 -a 192.168.2.37
----

. Run the `nvme connect-all` command across all the supported NVMe/TCP initiator-target LIFs across the nodes, and set the controller loss timeout period:
+
----
nvme connect-all -t tcp -w host-traddr -a traddr -l ctrl_loss_timeout_in_seconds
----
+
*Example output*
+
----
# nvme connect-all -t tcp -w 192.168.1.4 -a 192.168.1.31 -l -1
# nvme connect-all -t tcp -w 192.168.1.4 -a 192.168.1.32 -l -1
# nvme connect-all -t tcp -w 192.168.2.5 -a 192.168.1.36 -l -1
# nvme connect-all -t tcp -w 192.168.2.5 -a 192.168.1.37 -l -1
----
+
[NOTE]
NetApp recommends setting the `ctrl-loss-tmo` option with an indefinite value (such as -1) so that an NVMe subsystem continues trying to reconnect in the event of a path loss. 

== Validate NVMe-oF

You can use the following procedure to validate NVMe-oF.

.Steps

. Verify that in-kernel NVMe multipath is enabled:
+
----
cat /sys/module/nvme_core/parameters/multipath
Y
----

. Verify that the host has the correct controller model for the ONTAP NVMe namespaces:
+
----
cat /sys/class/nvme-subsystem/nvme-subsys*/model 
----
+
*Example output:*
+
----
NetApp ONTAP Controller
NetApp ONTAP Controller
----

. Verify the NVMe I/O service policy:
+
----
cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy 
----
+
*Example output:*
+
----
round-robin
round-robin
----

. Verify that the ONTAP namespaces are visible to the host:
+
----
nvme list
----
+
*Example output:*
+
----
Node		Generic		SN				Model
-------------------------------------------------------------
/dev/nvme1n1	/dev/mg1n1	814vWBNRwfBGAAAAAAAB	NetApp ONTAP Controller

Namespace	Usage		Format		FW			Rev	
-----------------------------------------------------------------
1		85.90		GB/85.90GB		4 KiB + 0 B		FFFFFFFF
----

. Verify that the controller state of each path is live and has the proper ANA status.
+
----
nvme list-subsys /dev/subsystem_name
----
+
[role="tabbed-block"]
====
.NVMe/FC 
--
[subs=+quotes]
----
# nvme list-subsys /dev/nvme1n1 nvme-subsys1 - NQN=nqn.1992-
08.com.netapp:sn.04ba0732530911ea8e8300a098dfdd91:subsystem.nvme_145_1
\
+- nvme2 fc traddr=nn-0x208100a098dfdd91:pn- 0x208200a098dfdd91,host_traddr=nn-0x200000109b579d5f:pn-0x100000109b579d5f *live optimized*
+- nvme3 fc traddr=nn-0x208100a098dfdd91:pn- 0x208500a098dfdd91,host_traddr=nn-0x200000109b579d5e:pn-0x100000109b579d5e *live optimized*
+- nvme4 fc traddr=nn-0x208100a098dfdd91:pn- 0x208400a098dfdd91,host_traddr=nn-0x200000109b579d5e:pn-0x100000109b579d5e *live non-optimized*
+- nvme6 fc traddr=nn-0x208100a098dfdd91:pn- 0x208300a098dfdd91,host_traddr=nn-0x200000109b579d5f:pn-0x100000109b579d5f *live non-optimized*
----
--

.NVMe/TCP 
--
[subs=+quotes]
----
nvme list-subsys /dev/nvme0n1 nvme-subsys0 - NQN=nqn.1992-
08.com.netapp:sn.37ba7d9cbfba11eba35dd039ea165514:subsystem.nvme_114_tcp_1
\
+- nvme0 tcp traddr=192.168.2.36 trsvcid=4420,host_traddr=192.168.1.4 *live optimized*
+- nvme1 tcp traddr=192.168.1.31 trsvcid=4420,host_traddr=192.168.1.4 *live optimized*
+- nvme10 tcp traddr=192.168.2.37 trsvcid=4420,host_traddr=192.168.1.4 *live non-optimized*
+- nvme11 tcp traddr=192.168.1.32 trsvcid=4420,host_traddr=192.168.1.4 *live non-optimized*
+- nvme20 tcp traddr=192.168.2.36 trsvcid=4420,host_traddr=192.168.2.5 *live optimized*
+- nvme21 tcp traddr=192.168.1.31 trsvcid=4420,host_traddr=192.168.2.5 *live optimized*
+- nvme30 tcp traddr=192.168.2.37 trsvcid=4420,host_traddr=192.168.2.5 *live non-optimized*
+- nvme31 tcp traddr=192.168.1.32 trsvcid=4420,host_traddr=192.168.2.5 *live non-optimized*
----
--
====

. Verify that the NetApp plug-in displays correct values for each ONTAP namespace device. 
+
[role="tabbed-block"]
====

.Column
--

`nvme netapp ontapdevices -o column`

Example output: 

----
Device	Vserver	Namespace Path
-----------------------------------------------------
/dev/nvme1n1 vserver_fcnvme_145 /vol/fcnvme_145_vol_1_0_0/fcnvme_145_ns

NSID	UUID							Size
--------------------------------------------------------
1		23766b68-e261-444e-b378-2e84dbe0e5e1	85.90GB
----
--

.JSON
--

`nvme netapp ontapdevices -o json`

Example output:
----
{
"ONTAPdevices" : [
{
  "Device" : "/dev/nvme1n1", "Vserver" : "vserver_fcnvme_145",
  "Namespace_Path" : "/vol/fcnvme_145_vol_1_0_0/fcnvme_145_ns", "NSID" : 1,
  "UUID" : "23766b68-e261-444e-b378-2e84dbe0e5e1", "Size" : "85.90GB",
  "LBA_Data_Size" : 4096,
  "Namespace_Size" : 20971520
}
]
}
----
--
====

== Discovery enhancements

Beginning with ONTAP 9.11.1, you create a persistent discovery controller for your SLES 15 SP4 host.

.Steps

. Verify that the discovery log page data is available and can be retrieved through the initiator port - target LIF combination:
+
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*Example output:*
+
----
Discovery Log Number of Records 8, Generation counter 18
=====Discovery Log Entry 0====== trtype: tcp
adrfam: ipv4
subtype: current discovery subsystem treq: not specified
portid: 0
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.2.117
eflags: explicit discovery connections, duplicate discovery information sectype: none
=====Discovery Log Entry 1====== trtype: tcp
adrfam: ipv4
subtype: current discovery subsystem treq: not specified
portid: 1
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.1.117
eflags: explicit discovery connections, duplicate discovery information sectype: none
=====Discovery Log Entry 2====== trtype: tcp
adrfam: ipv4
subtype: current discovery subsystem treq: not specified
portid: 2
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.2.116
eflags: explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 3====== trtype: tcp
adrfam: ipv4
subtype: current discovery subsystem treq: not specified
portid: 3
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.1.116
eflags: explicit discovery connections, duplicate discovery information sectype: none
=====Discovery Log Entry 4====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 0
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.2.117 eflags: not specified sectype: none
=====Discovery Log Entry 5====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 1
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.1.117 eflags: not specified sectype: none
=====Discovery Log Entry 6====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 2
trsvcid: 4420
subnqn: nqn.1992- 08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.2.116 eflags: not specified sectype: none
=====Discovery Log Entry 7====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 3
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.1.116 eflags: not specified sectype: none
----

. Create a Persistent Discovery Controller (PDC) connection to the discovery subsystem:
+
----
nvme discover -t tcp -w host-traddr -a traddr -p
----
+
*Example output:*
+
----
nvme discover -t tcp -w 192.168.1.16 -a 192.168.1.116 -p
----

. From the ONTAP controller, validate that the PDC is created:
+
----
vserver nvme show-discovery-controller -instance -vserver vserer_name
----
+
*Example output:*
+
----
Vserver Name: vs_CLIENT116 Controller ID: 00C0h
Discovery Subsystem NQN: nqn.1992- 08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery Logical Interface UUID: d23cbb0a-c0a6-11ec-9731-d039ea165abc Logical Interface: CLIENT116_lif_4a_1
Node: A400-14-124
Host NQN: nqn.2014-08.org.nvmexpress:uuid:12372496-59c4-4d1b-be09- 74362c0c1afc
Transport Protocol: nvme-tcp
Initiator Transport Address: 192.168.1.16
Host Identifier: 59de25be738348f08a79df4bce9573f3 Admin Queue Depth: 32
Header Digest Enabled: false Data Digest Enabled: false
Vserver UUID: 48391d66-c0a6-11ec-aaa5-d039ea165514
----


== Set up secure in-band authentication

Beginning with ONTAP 9.12.1 and later, secure, in-band authentication is supported over NVMe/TCP and NVMe/FC between your SLES 15 SP4 host and your ONTAP controller.

To set up secure authentication, each host or controller must be associated with a `DH-HMAC-CHAP` key which is a combination of the NQN of the NVMe host or controller and an authentication secret configured by the administrator. In order for an NVMe host or controller to authenticate its peer, it must recognize the key associated with the peer. 

.Steps

You can set up secure in-band authentication using the CLI or using a config JSON file. If you need to specify different dhcap keys for different subsystems, then you must use a config JSON file. 

[role="tabbed-block"]
====

.CLI
--

.Steps

. Obtain the host NQN:
+
----
cat /etc/nvme/hostnqn
----

. Generate the dhchap key for the SLES15 SP4 host:
+
----
nvme gen-dhchap-key -s optiona_secret -l key_length {32|48|64} -m HMAC_function {0|1|2|3} -n host_nqn 

•	-s secret key in hexadecimal characters to be used to initialize the host key
•	-l length of the resulting key in bytes
•	-m HMAC function to use for key transformation 
0 = none, 1- SHA-256, 2 = SHA-384, 3=SHA-512
•	-n host NQN to use for key transformation
----
+
*Example*:
+
In the following example, a random `dhchap` key with HMAC set to 3 (SHA-512) is generated.
+
----
# nvme gen-dhchap-key -m 3 -n nqn.2014-08.org.nvmexpress:uuid:d3ca725a- ac8d-4d88-b46a-174ac235139b
DHHC-
1:03:J2UJQfj9f0pLnpF/ASDJRTyILKJRr5CougGpGdQSysPrLu6RW1fGl5VSjbeDF1n1DEh 3nVBe19nQ/LxreSBeH/bx/pU=:
----

. On the ONTAP controller, add the host and specify both `dhchap` keys:
+
----
vserver nvme subsystem host add -vserver svm_name -subsystem subsystem -host-nqn host_nqn -dhchap-host-secret authentication_host_secret -dhchap-controller-secret authentication_controller_secret -dhchap-hash-function {sha-256|sha-512} -dhchap-group {none|2048-bit|3072-bit|4096-bit|6144-bit|8192-bit}
----

. On the host, connect to the ONTAP controller and specify both dhchap keys:
+
----
nvme connect -t tcp -w ip_address -a ip_address -n host_nqn -S authentication_host_secret -C authentication_controller_secret 
----

. Validate the `nvme connect authentication` command by verifying the host and controller dhchap keys: 
+
----
$cat /sys/class/nvme-subsystem/<nvme-subsysX>/nvme*/dhchap_secret
$cat /sys/class/nvme-subsystem/<nvme-subsysX>/nvme*/dhchap_ctrl_secret
----
+
*Example output for unidirectional configuration:*
+
----
SR650-14-114:~ # cat /sys/class/nvme-subsystem/nvme-subsys1/nvme*/dhchap_secret
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
SR650-14-114:~ # cat /sys/class/nvme-subsystem/nvme-subsys1/nvme*/dhchap_ctrl_secret
none
none
none
none
SR650-14-114:~ #
----
+
*Example output for bidirectional configuration:*
+
----
SR650-14-114:~ # cat /sys/class/nvme-subsystem/nvme-subsys6/nvme*/dhchap_ctrl_secret
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:

SR650-14-114:~ # cat /sys/class/nvme-subsystem/nvme-subsys6/nvme*/dhchap_secret
DHHC-1:03:ge5YncJ9V2u/qMyQPS1YjKSTtB7bmxAnnBZjR6KibBBrQaJqe+bBMkL6bubbPWwnzySxWkyHq3cuF5YusaTI5/mCIw8=:
DHHC-1:03:ge5YncJ9V2u/qMyQPS1YjKSTtB7bmxAnnBZjR6KibBBrQaJqe+bBMkL6bubbPWwnzySxWkyHq3cuF5YusaTI5/mCIw8=:
DHHC-1:03:ge5YncJ9V2u/qMyQPS1YjKSTtB7bmxAnnBZjR6KibBBrQaJqe+bBMkL6bubbPWwnzySxWkyHq3cuF5YusaTI5/mCIw8=:
DHHC-1:03:ge5YncJ9V2u/qMyQPS1YjKSTtB7bmxAnnBZjR6KibBBrQaJqe+bBMkL6bubbPWwnzySxWkyHq3cuF5YusaTI5/mCIw8=:
SR650-14-114:~ #
----

--

.JSON file
--
Note that `dhchap_key` corresponds to `dhchap_secret` and `dhchap_ctrl_key` corresponds to `dhchap_ctrl_secret`. 

.Steps

. Configure the JSON file.
+
----
# cat /etc/nvme/config.json 
[
 {
    "hostnqn":"nqn.2014-08.org.nvmexpress:uuid:12372496-59c4-4d1b-be09-74362c0c1afc",
    "hostid":"3ae10b42-21af-48ce-a40b-cfb5bad81839",
    "dhchap_key":"DHHC-1:03:Cu3ZZfIz1WMlqZFnCMqpAgn/T6EVOcIFHez215U+Pow8jTgBF2UbNk3DK4wfk2EptWpna1rpwG5CndpOgxpRxh9m41w=:"
 },

 {
    "hostnqn":"nqn.2014-08.org.nvmexpress:uuid:12372496-59c4-4d1b-be09-74362c0c1afc",
    "subsystems":[
        {
            "nqn":"nqn.1992-08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIENT116",
            "ports":[
               {
                    "transport":"tcp",
                    "traddr":"192.168.1.117",
                    "host_traddr":"192.168.1.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               },
               {
                    "transport":"tcp",
                    "traddr":"192.168.1.116",
                    "host_traddr":"192.168.1.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               },
               {
                    "transport":"tcp",
                    "traddr":"192.168.2.117",
                    "host_traddr":"192.168.2.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               },
               {
                    "transport":"tcp",
                    "traddr":"192.168.2.116",
                    "host_traddr":"192.168.2.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               }
           ]
       }
   ]
 }
]
----

. Connect to the ONTAP controller using the config JSON file.
+

----
nvme connect-all -J /etc/nvme/config.json
----
+
*Example output*:
+
----
traddr=192.168.2.116 is already connected
traddr=192.168.1.116 is already connected 
traddr=192.168.2.117 is already connected
traddr=192.168.1.117 is already connected
traddr=192.168.2.117 is already connected 
traddr=192.168.1.117 is already connected 
traddr=192.168.2.116 is already connected 
traddr=192.168.1.116 is already connected
traddr=192.168.2.116 is already connected 
traddr=192.168.1.116 is already connected
traddr=192.168.2.117 is already connected 
traddr=192.168.1.117 is already connected
----

. Verify that the dhcap secrets have been enabled for the respective controllers for each subsystem:
+
----
# cat /sys/class/nvme-subsystem/nvme-subsys0/nvme0/dhchap_secret
----
+
*Example output:*
+
----
DHHC-1:01:NunEWY7AZlXqxITGheByarwZdQvU4ebZg9HOjIr6nOHEkxJg:
----
+
----
# cat /sys/class/nvme-subsystem/nvme-subsys0/nvme0/dhchap_ctrl_secret
----
+
*Example output:*
+
----
DHHC-1:03:2YJinsxa2v3+m8qqCiTnmgBZoH6mIT6G/6f0aGO8viVZB4VLNLH4z8CvK7pVYxN6S5fOAtaU3DNi12rieRMfdbg3704=:
----
--
====


== Known issues 

The NVMe-oF host configuration for SLES 15 SP4 with ONTAP has the following known issues:

[cols="10,30,10",options="header"]
|===
|NetApp Bug ID	|Title	|Description
|1490498	| Host is non-operational at `crypto_ahash_digest()` during NVMe reauthentication |None
|1496739	| Host cannot disconnect after sending `auth_failure2` during reauthentication |None	
|===

//BURT 1529116 30 Jan 2023
//JIRA 1164 31 Aug 2023


